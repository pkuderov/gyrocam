Вопросы:
 * "Manhattan World" - переводить, нет?
 * стоит ли рядом с понятиями, методами, названиями чего-либо важного приводить в скобочках оригинальное и/или популярное название на ин.яз.?
Ответы:
---------------------------------------------------

Активно развивается область, связанная с созданием автономных роботов, транспортных средств. Область широкая и давно вышла за рамки военных нужд - высок интерес со стороны промышленности и населения (нужно про это вообще писать?). бла-бла-бла
Собственное движение автотехники полагается на системы позиционирования. 
Распространенные способы построения подобных систем: 
 * сонары и т.п.
 * гироскопы на основе инерциальных датчиков. Проблема –  накопление ошибки со временем.
 * системы глобального (спутникового) наведения – низкая точность в местах густой застройки, под кронами деревьев, под мостами (так ли это? да!), низкая точность в принципе при условии использования недорогих приемников и/или при небольших размерах (относительно максимально возможной точности) самого объекта.
Навигацию можно условно разделить на глобальную – определение абсолютных координат, локальную – определение координат относительно некоторых точек и персональную – позиционирование собственных частей, а так же на активную – координаты определяет сам объект навигации и пассивную – получение собственных координат извне.

Набирает популярность использование методов компьютерного зрения. Видеодатчики имеют маленький размер, энергопотребление, цену => есть интерес использовать их в системах позиционирования и навигации. Камеры потребительского класса легко доступны, для тестирования методов можно использовать их, в том числе камеры мобильных телефонов. Датчики на основе анализа изображений не имеют проблемы ИНС - накопления ошибки, при этом может достигаться довольно хорошая точность, сравнимая с датчиками гироскопов потребительского класса.
Популярные решения:
 * SLAM(simultaneous localization and mapping, метод одновременной навигации и составления карты / картирования) - используют Particle filters / Sequential Monte Carlo(SMC) или расширенный фильтр Калмана
 * SfM (Structure from motion) - видимо, то же, что и 3D reconstruction from 2D images.
Оба решения похожи тем, что они пытаются построить 3D модель окружающей среды, относительно которой происходит движение камеры.

Другой вариант – построение гироскопа на основе определения трехмерной ориентации по изображению без воссоздания модели окружающей среды. Данный метод основан на отслеживании ТСП по обнаруженным на изображении СЛ в условиях "Manhattan World" (во введении своими словами, а где-то дальше приткнуть про мв)
/* 
вот тут стоит кратко в 2-3 предложения описать, что такое "Manhattan World" и далее стараться его не касаться:
 * wiki http://en.wikipedia.org/wiki/User:Paulpop
 * probably original of such concept (pdf) http://papers.nips.cc/paper/1804-the-manhattan-world-assumption-regularities-in-scene-statistics-which-enable-bayesian-inference.pdf
*/

Плюсы конкретно данного метода:
 * в условиях "Manhattan World" изобилие линейных объектов правильной геометрической формы позволяет достигнуть высокой точности
 * число интересующих нас ТСП ограничено <= 3
 * ТСП не зависят от положения камеры - только от ее ориентации
 * робастность относительно случайных нестационарных объектов, попадающих в кадр (люди, транспортные средства и т.п.)

Методы на основе определения ТСП используются для:
 * навигации автономных транспортных средств, роботов
 * 3D реконструкции окружающей среды в условиях "Manhattan World"
 * калибровка камер и коррекция изображений


Метод коротко:
 * выделение сегментов линий на изображении
 * выделение наилучших кластеров СЛ, сходящихся в одной точке (или бесконечности), используя алгоритм RANSAC
 * (не работает) приведение координат сегментов линий в нормализованные координаты путем домножения слева на обратную матрицу калибровки
 * вычисление вектора направления ТСП на основе полученных кластеров СЛ путем приближенного решения задачи минимизации Ax = 0 методом SVD декомпозиции матрицы A
 * ортогонализация матрицы, составленной из векторов направлений ТСП
 * (нет) получение углов (крен, тангаж, рыскание) из матрицы поворота
 * (нет) связывание матриц поворота и кормление их расширенному фильтру Калмана (omgwtf)
 
Входные данные алгоритма - изображение с условием "Manhattan World".

1. Выделение сегментов линий
Первым этапом является выделение сегментов линий на изображении. Для решения данной задачи в оригинальной статье предлагается использовать метод Джиои и ... (Link4). (проверить, что написано во введение самой статьи Джиои) Это довольно новый алгоритм, отличающийся высокой скоростью за счет линейной зависимости сложности от размеров изображения по сравнению с другими алгоритмами, основанных на анализе связанных компонент градиента изображения. По быстродействию он уступает алгоритмам, основанным на преобразовании Хафа (Hough), но позволяет достичь более высокого качества.
В своем приложении я использовал реализацию алгоритма Джиои в библиотеке opencv версии 3.0.0. Ему отвечает класс cv::LineSegmentDetector (LSD), который принимает на вход изображение в градациях серого (в opencv тип CV_8UC1), и различные параметры настройки алгоритма. В своем приложении в качестве параметров настройки я использовал рекомендованные по умолчанию. 
Результатом работы модуля LSD является список найденных сегментов линий. Для каждого сегмента дается следующая информация:
 * координаты концов в пикселах в виде четверки целых чисел (тип данных opencv Vec4i)
 * ширина линии
 * точность, с которой он найден
 * число ложных срабатываний (number of false alarms) в области сегмента линии в виде логарифмической шкалы качества детектирования

2. Подготовка данных и предподсчеты
Получив результат работы детектора сегментов линий, я провожу фильтрацию сегментов по длине, отбрасывая слишком короткие меньше 20 символов. Во-первых, это позволяет значительно ускорить работу на последующих этапах. Во-вторых, мною было замечено, что короткие сегменты чаще относятся к ошибочным направлениям (не к искомым ТСП). Те же, что относятся к искомым ТСП за счет своей длины ухудшают точность вычислений, т.к. погрешность детектора в обнаружении одного из концов отрезка в 1 пиксел ведет к достаточно большой итоговой угловой погрешности.  
Далее я провожу подготовку структур данных к последующим этапам работы алгоритма, создавая на основе каждого отрезка, представленного четверкой целых чисел, объект структуры LineSegment, вычисляю и сохраняю следующие поля:
 * оригинальную четверку координат концов, полученных в виде объекта структуры Vec4i
 * координаты точек концов отрезка в нормализованных координатах и удобном формате типа cv::Point3d
 * середину отрезка в нормализованных координатах
 * уравнение линии, которую задает сегмент, в нормализованных координатах. Уравнение вычисляется как ltp(from, to) - см. теорию (векторное произведение точек концов отрезка)
Далее в формулах для ясности мы будем часто оперировать в терминах данной структуры: /*тут я пока пишу в виде обращения к полю, т.е. segment.line, segment.middle и т.п. В готовом варианте наверное либо вообще сегментом не пользоваться, либо в виде подписи-индекса*/ segment.from, segment.to и segment.middle - описанные выше точки, segment.line - описанное выше уравнение линии
 
3. Кластеризация с помощью RANSAC
Далее, я провожу кластеризацию сегментов линий, используя адаптивный алгоритм RANSAC. На каждом прогоне алгоритма вычисляется самый большой оставшийся кластер сегментов, линии которых пересекаются в одной точке с некоторой допустимой погрешностью. Полученный кластер объявляется соответствующим некоторой ТСП. Всего производится 3 запуска алгоритма.
Алгоритм состоит из последовательности итераций, состоящих из следующих шагов:
 * случайным образом выбирается пара сегментов линий
 * вычисляется точка их пересечения, которая объявляется потенциальной ТСП
 * далее проводится каждого сегмента линии на предмет принадлежности его потенциальной ТСП путем вычисления функция расстояния до ТСП по формуле:
	
		Point3d l = lineThroughPoints(segment.middle, vp);
		double d = incidence(l, segment.from) / norm12(l);
		return abs(d) <= distanceEpsilon 
			&& abs(asin(d / norm(segment.middle - segment.from))) <= angleEpsilon;
			
, где 
	static const double distanceEpsilon = 2; // 2 pixel
	static const double angleEpsilon = 0.04; // ~1% pi or ~2 degree
Таким образом для имеющейся потенциальной ТСП определяется множество соответствующих ей сегментов. Назовем содержащиеся в нем сегменты внутренними, а все остальные - внешними по отношению к данной vp. Обозначим также их отношение как r. Чем выше число r, тем более подходящей считается ТСП.
Число итераций алгоритма определяется адаптивно следующим образом. Представим, что мы ищем некоторую подходящую нам ТСП. Вероятность того, что во всем множестве сегментов мы случайно выберем оба внутренних сегмента равна r^2. Вероятность же выбора хотя бы одной внешней - 1 - r^2. Соответственно вероятность события, когда за k итераций ни разу не будет выбрана пара внутренних сегментов равна: 
    P(k) = (1 - r^2)^k
Заметим, что P(k) - строго убывающая функция. Теперь нам хотелось бы гарантировать с вероятностью p, что за некоторое количество итераций k будет выбрана хотя бы одна пара внутренних сегментов линий:
    p >= 1 - P(k)
=>  P(k) >= 1 - p
=>  (1 - r^2)^k >= 1 - p
логарифмируем обе стороны:
=>  k >= log(1 - p) / log (1 - r^2)
Истинное значение r неизвестно, но его можно аппроксимировать снизу r', соответствующим наилучшей из найденных за текущие k' итераций ТСП.
После каждого запуска алгоритма RANSAC внутренние сегменты для найденной ТСП удаляются из выборки и в последующих запусках не участвуют. В итоге после 3х последовательных запусков алгоритма мы имеем 3 кластера сегментов линий, каждому из которых соответствует довольно грубая оценка ТСП.

4. Уточнение результата ТСП
Так как координаты сегментов линий имеют приблизительный характер, ТСП, выбранная на основе случайной пары из этого множества, не "учитывает" голоса остальных сегментов. Поэтому производится уточнение координат ТСП через минимизацию функционала, учитывающего все сегменты соответствующего ТСП множеста.
Рассмотрим сегменты одного из множеств. Линии, заданные ими, пересекаются в некоторой точке vp, т.е.
    для каждого segment @ Cluster: ltp(segment.line, vp) = segment.line * vp = 0
Или для всего множества:
    [segment1.line .. segmentN.line]T * vp = 0
Таким образом имеется переопределенная система уравнений. Так как данное уравнение имеет приблизительный характер, на самом деле мы хотим найти такую нетривиальную точку vp, которая минимизирует функционал в левой части, а именно:
    vp = argmin(LT * vp)
Существуют разные методы решения данной задачи. В данной работе мы выбрали метод, использующий сингулярное разложение матрицы LT.

-----------------------Теория-------------------
1. Геометрия ТСП
Теория точек схождения перспективы (ТСП) рассматривается обычно в терминах проективной геометрии, изучающей геометрические свойства, являющихся инвариантными относительно проективных преобразований, а также сами эти преобразования. Проецирование трехмерной сцены на двухмерную плоскость изображения, осуществляемое фото- или видеокамерой, – одно из таких преобразований.
Одной из интересующих нас особенностей проективного преобразования является тот факт, что параллельность прямых не является инвариантом относительно него. Это значит, что параллельные в евклидовом пространстве прямые при проективном преобразовании всегда пересекаются в некоторой точке. Эта точка может быть как конечной, так и бесконечной, то есть идельной. Далее будет более подробно рассмотрены свойства проективной геометрии и введена модель булавочного отверстия, которая описывает искомое нами преобразование трехмерной сцены на двухмерную плоскость изображения.

1.1. Проективное преобразование и однородные координаты, модель булавочного отверстия, ТСП
В проективной геометрии точки представлены в однородных координатах. Например, рассмотрим точку в двухмерном евклидовом пространстве (x, y) @ R2. Чтобы представить ее на проективной плоскости, необходимо лишь добавить третью компоненту z, равную 1, т.е. (x, y, 1) @ P2. Более того, для любого ненулевого a (ax, ay, a) = (x, y, 1). В случае нулевого a координаты точки вырождаются в точку (0, 0, 0), которая не включена в P2.
Рассмотрим уравнение прямой на двухмерной евклидовой плоскости:
	ax + by + c = 0
Точки (x, y), и только они, удовлетворяющие данному уравнению являются лежащими на данной прямой. Теперь заметим, что уравнение (*) можно переписать следующим образом:
	ax + by + c*1 = aX + bY + cZ = 0
Таким образом мы определили все точки (x, y, 1) = (X / Z, Y / Z, 1) = (X, Y, Z) проективного пространства, лежащие на прямой. Заметим также, что aX + bY + cZ = l * p = 0, где l = (a, b, c), p = (X, Y, Z), a * - скалярное произведение. Во-первых, важным свойством проективной геометрии является то, что уравнение линии задается вектором той же размерности, что и точки (однако несмотря на симметрию представления всегда стоит помнить какого типа объект - точка или прямая). Во-вторых, имеет место весьма красивое и простое выражение связывающее точки и проходящие через них линии в виде равенства нулю скалярного произведения.
Не вдаваясь в подробности, запишем это и другие важные уравнения проективной геометрии, которые так или иначе понадобятся нам в работе:
 * проверка принадлежности точки прямой incidence(p1, p2) = p1 * p2
 * прямая через две точки ltp(p1, p2) = p1 x p2, где x - векторное произведение
 * точка пересечения двух прямых intersection(l1, l2) = l1 x l2

Чтобы вернуться из P2 обратно в R2, достаточно поделить координаты точки на z-координату, то есть (X, Y, Z) = (X / Z, Y / Z, 1) = (x, y, 1) @ P2 ~ (x, y) @ R2. Из данной процедуры сразу видно, что P2 ( R2, так как содержит элементы с z = 0. Эти точки составляют довольно важно подмножество P2 и называются идальными. Еще их называют точками в бесконечности, так как они соответствуют предельным точкам, лежащим бесконечно далеко от начала координат. Несмотря на свой особый вид, данные точки никаким специальным образом не обрабатываются, то есть рассматриваются абсолютно также как и обычные. Все идеальные точки лежат на одной прямой, называемой идеальной или прямой в бесконечности.

Также заметим, что точкам p(X, Y, Z) = (x, y, 1) @ P2 можно поставить в соответствие прямую, проходящую через начало координат и точку p`(x, y, 1) @ R3 с выколотой точкой (0, 0, 0). Таким же образом линия l(a, b, c) на проективной плоскости может быть визуализирована в R3 плоскостью, образованной началом координат и перпендикуляром к l`(a, b, c). Тогда точкам с координатами (x, y, 1) в R3 соответствует плоскость Z = 1, идеальным точкам соответствуют точки на Z = 0, а идеальной прямой сама плоскость Z = 0.
Данная связь между R3 и P2 может быть легко продолжена до связи между P3 (добавлением к точкам R3 четвертой координаты 1) и P2. Такая связь очень хорошо подходит для описания преобразования проецирования трехмерной сцены на двухмерную плоскость изображения. 

Рассмотрим точку в R3 p(X, Y, Z). Для того, чтобы прибавить к ней вектор t(Tx, Ty, Tz), мы можем воспользоваться следующим матричным выражением:
[p + t] = [ E t] * [p]
[1    ]   [ 0 1]   [1]
Похожим образом выражается поворот точки p и умножение каждой из его координат на независимый коэффициент d(dx, dy, dz):
[p'] = [R 0] * [p]
[1 ]   [0 1]   [1]

[dx * X]   [dx 0  0  0]  
[dy * Y] = [0  dy 0  0] * [p] 
[dz * Z]   [0  0  dz 0]   [1]
[1     ]   [0  0  0  1]

Можно заметить, что в данных выражениях точка p @ R3 представлена в нормализованных координатах P3 (X, Y, Z, 1). Также очевидно, что данные выражения остаются верными, если и для точкек вида alpha * p = (alpha X, alpha Y, alpha Z, alpha):
	alpha * (M * p) = M * (alpha * p).
Интересно рассмотреть как данные преобразования влияют на идеальные точки q(X, Y, Z, 0). Простой подстановкой проверяется, что:
 * перенос на вектор t оставляет идеальную точку на месте
 * поворот действует на идеальную точку абсолютно также, как и на конечную
 * масштабирование на вектор d(dx, dy, dz) действует аналогично действию на конечную точку

Теперь рассмотрим связь между системами координат камеры и мировой системой координат. Пусть в мировой системе координаты камеры представлены точкой t, а матрица поворота R связывает соответствующие оси систем, тогда выражения связи имеет вид:
	pw -> R(pw - t) = pc
, где pw - точка в мировой системе, а pc - в координатах системы камеры.
	pc = Rpw - Rt
Если же воспользоваться нормализованными координатами, получится следующее:
	[pc] = [R -Rt] * [pw] = [R 0] * [I -t] * [pw]
	[1 ]   [0   1]   [1 ]   [0 1]   [0  1]   [ 1]
Матрица M, определенная как:
	M = [R 0] * [I -t]
	    [0 1]   [0  1]
, задает матрицу перехода между системами координат. Матрицы R и t задают внешние (extrinsic) параметры камеры - ориентацию и позицию - в мировых координатах.

Одна из самых простых и обычно используемых моделей для конечной проективной камеры - модель булавочного отверстия или модель камеры обскуры (pinhole camera), в которой точки p(X, Y, Z) @ R3 проецируются на двухмерную плоскость по правилу:
 (x, y) = (fX / Z, fY / Z)
или в нормализованных координатах:
 (x, y, 1) = (f X/Z, fY / Z) = |при Z != 0| = (X, Y, Z / f) = (fX, fY, Z)
Данное правило может быть записано в виде матрицы проекции:
	[fX]   [f 0 0 0]   [X]
	[fY] = [0 f 0 0] = [Y]
	[Z ]   [0 0 1 0]   [Z]
	                   [1]
Очевидно также, что вектор [0 0 0 1]T - является нуль-вектором нуль-пространства данного преобразования.
Работая с реальными камерами и точками на полученных с них изображениях, удобнее иметь дело с координатами, выраженными в пикселах нежели, например, в миллиметрах. Перевод координат требует информации о линейных размерах пиксела (например, в миллиметрах) и координат главной точки (principal point), которой соответствует центр изображения (точка пересечения оптической оси камеры с плоскостью изображения), так как в общем случае она может не совсем точно совпадать с центром матрицы камеры (более того, довольно часто центр координат в пикселах определяется одним из углов изображения).
За такого рода перевод координат отвечает так называемая матрица калибровки камеры K, которая задает внутренние (intrinsic) параметры камеры и предполагается неизменяемой во времени:
K = [ f/mx s    px ]
    [ 0    f/my py ]
	[ 0    0    1  ]
, где 
	* f - фокусное расстояние камеры в некоторой единице длины (обычно в мм или дюймах), 
	* mx, my - линейные размеры пиксела, выраженные в той же единице длины, что и f. Таким образом f / mx и f / my имеют размерность пикселов (мм / (мм / px) = px),
	* s - коэффициент ассиметрии камеры
	* px, py - координаты главной точки в пикселах.
Большинство цифровых камер на основе приборов с зарядовой связью (ПЗС) имеют квадратные пикселы (mx = my), нулевую ассиметрию (s = 0) и главную точку, расположенную близко к центру изображения.

! возможно стоит сказать про дисторсию, что она есть, но в данной работе мы ей принебрегаем

Теперь мы готовы выразить проективное преобразование, отвечающее отображению трехмерной сцены на двухмерную плоскость изображения:
	F: P3 -> P2, F(p) = p' = KR[I | -t] p

Рассмотрим прямую в P3, заданную как X(alpha) = A + alpha * D, где А - точка на этой прямой, D(d, 0) - направляющий вектор и d @ R3, alpha @ R. Проекция этой прямой:
x(alpha) = P(X(alpha)) = P(A) + alpha * P(D) = P(A) + alpha * KR[I | -t]D = P(A) + alpha * KRd
, так как [I | -t]D = d.
ТСП vp @ P2, соответствующая направлению d, является предельной точкой для проекции линии x(alpha) при alpha -> inf:
    vp = lim x(alpha) = lim( P(A) + alpha * KRd) = KRd
В системе координат, связанной с камерой R = I, поэтому:
    vp = Kd
Из полученного результата можно заключить, что:
 * ТСП vp не зависит от положения t камеры
 * существует взаимно однозначное отношение между vp и вектором направления прямой в трехмерном пространстве
Будем называть две ТСП ортогональными, если ортогональны векторы направления соответствующих им прямых. ТСП, которые являются идеальными, называются бесконечными, иначе - конечными.

...вот тут про Manhattan World assumption и прочее..
Большинство методов, основанных на обнаружении ТСП, работают в предположении, что на изображениях можно выделить некоторый набор сегментов линий, соответствующих взаимно ортогональным направлениям, т.е. имеющих ортогональные ТСП. Именно поэтому данные методы способны показывать хорошие результаты на изображениях помещений и городских пейзажах - объекты окружающего нас мира довольно часто имеют правильные геометрические формы и расставлены параллельно / перпендикулярно друг другу. Например, столы, полки, окна или витрины, пол, стены и потолок - внутри помещений, дома, дороги и разметка на них, окна домов - вне помещений.

2. Обнаружение ТСП
2.1. Обнаружение СЛ. Вкратце преобразование Хо (Хаф, Hough Transform) и анализ связанных компонент ориентаций градиента изображения, возможно про Canny детектор, кратко про LSD (pdf)
Выбрали  анализ ... почему?
Lsd - O(img.size()), but slower than Hough
2.2. Кластеризация СЛ. RANSAC, можно (нужно! но, возможно, не здесь, а дальше в "что можно улучшить") заикнуться про J-Linkage (введение в статье pdf - сравниваются разные способы кластеризации)
RANSAC выбрали, потому что популярное решение.
Расписать функцию расстояния d(vp,l), как в статье, как делаю я.
Расписать как выбирается число итераций алгоритма (вывод формулы) +
На данном этапе выработана грубая оценка ТСП
2.3. Уточнение ТСП
Описать математически текущую ситуацию - пучок линий сходится примерно в одной точке. Какое уравнение связывает их в идеале.
Значит решаем Ax = 0 приближенно. Что делать, если система не переопределена (у меня сейчас просто упадет программа!)?
Какие существуют способы приближенного решения данной задачи? LSQM, SVD, smth else
Почему мы не решаем ее тут, а переходим в нормализованные координат изображения? Что это такое вообще, зачем? В честь кого это делается? [Cipolla]
Получили нулевые направления, что дальше?
2.4. Определение ориентации по ТСП
Есть матрица D = [d1, d2, d3]. Если только две приблизительно ортогональны (или 3ей не нашли вообще), 3ю вычисляем на основе их через векторное произведение.
Объясняю, что D скорее всего не ортогональна => можно ортогонализовать. Как? SVD! D' = u * vt
Приводим матрицу нулевых направлений 

Матрица относительного поворота R = D2 D1t
At = A-1, т.к. ортогональная => alpha(R) = alpha(D2) + alpha(D1t) = alpha(D2) - alpha(D1)

Расширенный фильтр Калмана (http://en.wikipedia.org/wiki/Extended_Kalman_filter): 
In estimation theory, the extended Kalman filter (EKF) is the nonlinear version of the Kalman filter which linearizes about an estimate of the current mean and covariance. In the case of well defined transition models, the EKF has been considered[1] the de facto standard in the theory of nonlinear state estimation, navigation systems and GPS
Disadvantages of the extended Kalman filter
Unlike its linear counterpart, the extended Kalman filter in general is not an optimal estimator (of course it is optimal if the measurement and the state transition model are both linear, as in that case the extended Kalman filter is identical to the regular one). In addition, if the initial estimate of the state is wrong, or if the process is modeled incorrectly, the filter may quickly diverge, owing to its linearization. Another problem with the extended Kalman filter is that the estimated covariance matrix tends to underestimate the true covariance matrix and therefore risks becoming inconsistent in the statistical sense without the addition of "stabilising noise".

SfM:
Structure from motion (SfM) is a range imaging technique; it refers to the process of estimating three-dimensional structures from two-dimensional image sequences which may be coupled with local motion signals. It is studied in the fields of computer vision and visual perception. In biological vision, SfM refers to the phenomenon by which humans (and other living creatures) can recover 3D structure from the projected 2D (retinal) motion field of a moving object or scene.